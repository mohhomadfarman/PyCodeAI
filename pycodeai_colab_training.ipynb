{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xk_Vfist5oAW"
      },
      "source": [
        "# PyCodeAI - Google Colab Training (GitHub Version)\n",
        "\n",
        "This notebook trains your PyCodeAI model using code from GitHub and saves the results to Google Drive.\n",
        "\n",
        "## Instructions\n",
        "\n",
        "1.  **Configure**: Set your GitHub Repository URL in the first code cell.\n",
        "2.  **Mount Drive**: Run the cell to connect Google Drive (for saving the trained model).\n",
        "3.  **Run All**: Run all cells to clone, install, and train."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Cy-ANoS5oAW",
        "outputId": "17b8f7d9-75fc-496b-8dc1-db09d3bea9be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# CONFIGURATION\n",
        "# Replace this with your repository URL\n",
        "GITHUB_REPO = 'https://github.com/mohhomadfarman/PyCodeAI.git'\n",
        "BRANCH = 'main'  # or 'master'\n",
        "\n",
        "# This is where the model will be SAVED in your Google Drive\n",
        "DRIVE_SAVE_PATH = '/content/drive/MyDrive/PyCodeAI_Models'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUmVK-Wn5oAX",
        "outputId": "a3e88cbb-db14-4d66-8a82-bd86d0d7cf19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cupy-cuda12x\n",
            "  Downloading cupy_cuda12x-13.6.0-cp312-cp312-manylinux2014_x86_64.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: numpy<2.6,>=1.22 in /usr/local/lib/python3.12/dist-packages (from cupy-cuda12x) (2.0.2)\n",
            "Collecting fastrlock>=0.5 (from cupy-cuda12x)\n",
            "  Downloading fastrlock-0.8.3-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl.metadata (7.7 kB)\n",
            "Downloading cupy_cuda12x-13.6.0-cp312-cp312-manylinux2014_x86_64.whl (112.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.9/112.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastrlock-0.8.3-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.9/53.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fastrlock, cupy-cuda12x\n",
            "Successfully installed cupy-cuda12x-13.6.0 fastrlock-0.8.3\n"
          ]
        }
      ],
      "source": [
        "# 1. Mount Google Drive\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create the save directory if it doesn't exist\n",
        "os.makedirs(DRIVE_SAVE_PATH, exist_ok=True)\n",
        "print(f\"Models will be saved to: {DRIVE_SAVE_PATH}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TGNqe4F5oAX",
        "outputId": "2d291c02-94d1-4e52-e8d1-fd3bb5be34e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ERROR: Path not found: /content/drive/MyDrive/ColabNotebooks/PyCodeAI\n",
            "Please upload your PyCodeAI folder to Google Drive and update the path above.\n"
          ]
        }
      ],
      "source": [
        "# 2. Clone Repository & Install Dependencies\n",
        "!git clone {GITHUB_REPO} PyCodeAI_Repo\n",
        "%cd PyCodeAI_Repo\n",
        "!git checkout {BRANCH}\n",
        "!git pull origin {BRANCH}  # Ensure we have the latest\n",
        "\n",
        "# Install cupy for GPU\n",
        "!pip install cupy-cuda12x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_ohlOhS5oAX"
      },
      "outputs": [],
      "source": [
        "# 3. Check for Existing Model\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# If you have a 'best_model.npz' in your Drive, we can copy it here to resume training\n",
        "# Uncomment the lines below if you want to pull a model FROM Drive\n",
        "# DRIVE_MODEL = os.path.join(DRIVE_SAVE_PATH, 'best_model.npz')\n",
        "# if os.path.exists(DRIVE_MODEL):\n",
        "#     print(\"Found model in Drive, copying to local workspace...\")\n",
        "#     shutil.copy(DRIVE_MODEL, 'best_model.npz')\n",
        "\n",
        "if os.path.exists('best_model.npz'):\n",
        "    print(\"Starting training from existing 'best_model.npz'...\")\n",
        "else:\n",
        "    print(\"No 'best_model.npz' found. Starting fresh training (or finding it in repo).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eo8fS4EV5oAX"
      },
      "outputs": [],
      "source": [
        "# 4. Run Training\n",
        "# - Resumes from best_model.npz (if it exists)\n",
        "# - Saves to best_model_new.npz\n",
        "# - Creates a NEW tokenizer file\n",
        "\n",
        "# Protect original tokenizer\n",
        "!cp tokenizer.json tokenizer_new.json 2>/dev/null || echo \"No tokenizer.json found, will build new one.\"\n",
        "\n",
        "!python cli.py train \\\n",
        "    --device gpu \\\n",
        "    --load-model best_model.npz \\\n",
        "    --output-model best_model_new.npz \\\n",
        "    --output-tokenizer tokenizer_new.json \\\n",
        "    --epochs 5 \\\n",
        "    --batch-size 32 \\\n",
        "    --log-interval 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. Save Results to Drive\n",
        "import shutil\n",
        "import datetime\n",
        "\n",
        "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "new_model_name = f\"best_model_{timestamp}.npz\"\n",
        "new_token_name = f\"tokenizer_{timestamp}.json\"\n",
        "\n",
        "print(f\"Backing up to Drive as {new_model_name}...\")\n",
        "\n",
        "# Copy model\n",
        "if os.path.exists(\"best_model_new.npz\"):\n",
        "    shutil.copy(\"best_model_new.npz\", os.path.join(DRIVE_SAVE_PATH, new_model_name))\n",
        "    # Also update the 'latest' one\n",
        "    shutil.copy(\"best_model_new.npz\", os.path.join(DRIVE_SAVE_PATH, \"best_model_latest.npz\"))\n",
        "    print(\"Model saved.\")\n",
        "else:\n",
        "    print(\"ERROR: best_model_new.npz not found!\")\n",
        "\n",
        "# Copy tokenizer\n",
        "if os.path.exists(\"tokenizer_new.json\"):\n",
        "    shutil.copy(\"tokenizer_new.json\", os.path.join(DRIVE_SAVE_PATH, new_token_name))\n",
        "    shutil.copy(\"tokenizer_new.json\", os.path.join(DRIVE_SAVE_PATH, \"tokenizer_latest.json\"))\n",
        "    print(\"Tokenizer saved.\")\n",
        "else:\n",
        "    print(\"WARNING: tokenizer_new.json not found!\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}