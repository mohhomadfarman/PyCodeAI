{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# PyCodeAI - Google Colab Training\n",
                "\n",
                "This notebook allows you to train your PyCodeAI model using Google Colab's free GPU.\n",
                "\n",
                "## Instructions\n",
                "\n",
                "1.  **Upload Project**: Zip your entire `PyCodeAI` folder and upload it to your Google Drive.\n",
                "2.  **Mount Drive**: Run the cell below to mount your Google Drive.\n",
                "3.  **Navigate**: Change the directory path to where you uploaded `PyCodeAI`.\n",
                "4.  **Train**: Run the training cell. It will resume from `best_model.npz` and save to `best_model_new.npz`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Mount Google Drive\n",
                "from google.colab import drive\n",
                "drive.mount('/content/drive')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. Install Dependencies\n",
                "# We need cupy for GPU acceleration\n",
                "!pip install cupy-cuda12x"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3. Navigate to Project Directory\n",
                "import os\n",
                "\n",
                "# CHANGE THIS PATH to match where you uploaded the folder in your Drive\n",
                "# Example: '/content/drive/MyDrive/PyCodeAI'\n",
                "PROJECT_PATH = '/content/drive/MyDrive/PyCodeAI'\n",
                "\n",
                "if os.path.exists(PROJECT_PATH):\n",
                "    os.chdir(PROJECT_PATH)\n",
                "    print(f\"Current working directory: {os.getcwd()}\")\n",
                "else:\n",
                "    print(f\"ERROR: Path not found: {PROJECT_PATH}\")\n",
                "    print(\"Please upload your PyCodeAI folder to Google Drive and update the path above.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4. Resume Training\n",
                "# This command will:\n",
                "# - Use the GPU (--device gpu)\n",
                "# - Load your existing best model (--load-model best_model.npz)\n",
                "# - Save the result to a NEW file (--output-model best_model_new.npz)\n",
                "# - Use a cloned tokenizer so the original is untouched (--output-tokenizer tokenizer_new.json)\n",
                "\n",
                "# Create a copy of the tokenizer first so we don't overwrite the original\n",
                "!cp tokenizer.json tokenizer_new.json\n",
                "\n",
                "!python cli.py train \\\n",
                "    --device gpu \\\n",
                "    --load-model best_model.npz \\\n",
                "    --output-model best_model_new.npz \\\n",
                "    --output-tokenizer tokenizer_new.json \\\n",
                "    --epochs 5 \\\n",
                "    --batch-size 32 \\\n",
                "    --log-interval 10"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 5. (Optional) Verify Generation with New Model\n",
                "# Test the newly trained model\n",
                "\n",
                "!python cli.py generate \"def fibonacci(n):\" \\\n",
                "    --model-path best_model_new.npz \\\n",
                "    --tokenizer-path tokenizer_new.json \\\n",
                "    --max-tokens 100"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}